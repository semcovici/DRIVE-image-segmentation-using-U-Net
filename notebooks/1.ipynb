{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 00:34:58.186579: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-23 00:34:58.212197: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-23 00:34:58.219709: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-23 00:34:58.237602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-23 00:34:59.989416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/pesquisa/segmentation-of-blood-vessels-in-retinal-images/.venv/lib/python3.11/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.16 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from itertools import product\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "import segmentation_models as sm\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.dataloader import Dataloder\n",
    "from data.dataset import Dataset\n",
    "from data.data_utils import get_validation_augmentation,get_preprocessing,get_training_augmentation\n",
    "from visualization.viz_utils import visualize, denormalize\n",
    "import json\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/raw/'\n",
    "PATH_MODELS = \"../models/\"\n",
    "PATH_LOGS = \"../logs/\"\n",
    "RESULTS_PATH = \"../results/\"\n",
    "\n",
    "# define os paths dos dados\n",
    "x_train_dir = os.path.join(DATA_DIR, 'training', 'input')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'training', 'target')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test', 'input')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'test', 'target')\n",
    "\n",
    "\n",
    "# Gerar lista de IDs\n",
    "train_ids = ['%02d' % i for i in range(21, 41)]\n",
    "test_ids = ['%02d' % i for i in range(1, 21)]\n",
    "\n",
    "# Dividir IDs de treinamento em conjuntos de treinamento e validação\n",
    "val_ids = train_ids[-4:]\n",
    "train_ids = train_ids[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 00:35:02.860565: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n",
      "2024-09-23 00:35:02.860609: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: pop-os\n",
      "2024-09-23 00:35:02.860615: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: pop-os\n",
      "2024-09-23 00:35:02.860783: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 560.35.3\n",
      "2024-09-23 00:35:02.860808: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 555.58.2\n",
      "2024-09-23 00:35:02.860813: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:252] kernel version 555.58.2 does not match DSO version 560.35.3 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "BACKBONE = 'efficientnetb3'\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.0001\n",
    "EPOCHS = 3\n",
    "n_classes = 1\n",
    "\n",
    "# Definir otimizador\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Definir perda e métricas\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), 'accuracy', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_list = [\n",
    "    'sigmoid', \n",
    "    # 'softmax'\n",
    "            ]\n",
    "augmentation_list=[\n",
    "    # False,\n",
    "   True\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/pesquisa/segmentation-of-blood-vessels-in-retinal-images/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 9s/step - accuracy: 0.8073 - f1-score: 0.1595 - iou_score: 0.0868 - loss: 0.9280 - precision: 0.1293 - recall: 0.2069 - val_accuracy: 0.8820 - val_f1-score: 0.1317 - val_iou_score: 0.0705 - val_loss: 0.9133 - val_precision: 0.1715 - val_recall: 0.1073 - learning_rate: 1.0000e-04\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 00:39:06.299762: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/usr/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-09-23 00:39:06.377407: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.0000e+00 - f1-score: 0.0000e+00 - iou_score: 0.0000e+00 - loss: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/pesquisa/segmentation-of-blood-vessels-in-retinal-images/.venv/lib/python3.11/site-packages/keras/src/callbacks/early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,f1-score,iou_score,loss,precision,recall\n",
      "  current = self.get_monitor_value(logs)\n",
      "/home/semcovici/pesquisa/segmentation-of-blood-vessels-in-retinal-images/.venv/lib/python3.11/site-packages/keras/src/callbacks/model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n",
      "/home/semcovici/pesquisa/segmentation-of-blood-vessels-in-retinal-images/.venv/lib/python3.11/site-packages/keras/src/callbacks/callback_list.py:96: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,f1-score,iou_score,loss,precision,recall,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6s/step - accuracy: 0.8414 - f1-score: 0.2515 - iou_score: 0.1442 - loss: 0.9001 - precision: 0.2084 - recall: 0.3183 - val_accuracy: 0.8695 - val_f1-score: 0.2459 - val_iou_score: 0.1402 - val_loss: 0.9127 - val_precision: 0.2381 - val_recall: 0.2547 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "for activation, augmentation in product(activation_list, augmentation_list):\n",
    "\n",
    "    model_name = f'model_{BACKBONE}_{activation}_aug={augmentation}'\n",
    "    \n",
    "    valid_aug = None\n",
    "    train_aug = None\n",
    "    \n",
    "    \n",
    "    if augmentation:\n",
    "        valid_aug = get_validation_augmentation()\n",
    "        train_aug = get_training_augmentation()\n",
    "        \n",
    "    # Criar modelo\n",
    "    model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
    "    # Compilar modelo\n",
    "    model.compile(optimizer=optim, loss=total_loss, metrics=metrics)\n",
    "    \n",
    "    preprocessing = get_preprocessing(preprocess_input)\n",
    "\n",
    "\n",
    "    # Dataset para imagens de treinamento\n",
    "    train_dataset = Dataset(\n",
    "        x_train_dir,\n",
    "        y_train_dir,\n",
    "        ids=train_ids,\n",
    "        dataset_name='training',\n",
    "        augmentation=train_aug,\n",
    "        preprocessing=preprocessing,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Dataset para imagens de validação\n",
    "    valid_dataset = Dataset(\n",
    "        x_train_dir,\n",
    "        y_train_dir,\n",
    "        ids=val_ids,\n",
    "        dataset_name='training',\n",
    "        augmentation=valid_aug,\n",
    "        preprocessing=preprocessing,\n",
    "    )\n",
    "\n",
    "    # Dataset para imagens de teste\n",
    "    test_dataset = Dataset(\n",
    "        x_test_dir,\n",
    "        y_test_dir,\n",
    "        ids=test_ids,\n",
    "        dataset_name='test',\n",
    "        augmentation=valid_aug,\n",
    "        preprocessing=preprocessing,\n",
    "    )\n",
    "\n",
    "    train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dataloader = Dataloder(valid_dataset, batch_size=1, shuffle=False)\n",
    "    test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # # Verificar formas para erros\n",
    "    assert train_dataloader[0][0].shape == (BATCH_SIZE, 256, 256, 3)\n",
    "    assert train_dataloader[0][1].shape == (BATCH_SIZE, 256, 256, n_classes)\n",
    "\n",
    "\n",
    "\n",
    "    model_weights = PATH_MODELS + f'weights/best_{model_name}.weights.h5'\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10),\n",
    "        ModelCheckpoint(PATH_MODELS + f'model_file/best_{model_name}.keras', save_best_only=True, monitor='val_loss'),\n",
    "        ModelCheckpoint(model_weights, save_weights_only=True, save_best_only=True, mode='min'),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "        TensorBoard(log_dir=PATH_LOGS),\n",
    "        CSVLogger(PATH_MODELS + f'training_log_{model_name}.csv')\n",
    "    ]\n",
    "\n",
    "    # Treinar modelo\n",
    "    history = model.fit(\n",
    "        train_dataloader,\n",
    "        steps_per_epoch=len(train_dataloader),\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=valid_dataloader,\n",
    "        validation_steps=len(valid_dataloader),\n",
    "    )\n",
    "    \n",
    "    json.dump(history.history, open(RESULTS_PATH + f\"history/history_{model_name}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Avaliação do Modelo\n",
    "\n",
    "# Carregar os melhores pesos\n",
    "model.load_weights(model_weights)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "scores = model.evaluate(test_dataloader)\n",
    "\n",
    "print(\"Loss: {:.5}\".format(scores[0]))\n",
    "for metric, value in zip(metrics, scores[1:]):\n",
    "    print(\"mean {}: {:.5}\".format(metric.__name__ if type(metric) != str else metric, value))\n",
    "\n",
    "# # Visualização dos resultados no conjunto de teste\n",
    "\n",
    "for i in range(5):\n",
    "    image, gt_mask = test_dataset[i]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image).round()\n",
    "    \n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        ground_truth_mask=gt_mask.squeeze(),\n",
    "        predicted_mask=pr_mask.squeeze(),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
