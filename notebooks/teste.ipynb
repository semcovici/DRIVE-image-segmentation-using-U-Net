{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726457390.126903 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.168692 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.176298 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.183801 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.191325 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.193987 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.384368 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.385916 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1726457390.387339 1598788 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-16 00:29:50.388549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 752 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for InitSchema\n  Value error, If 'border_mode' is set to 'BORDER_CONSTANT', 'value' must be provided. [type=value_error, input_value={'min_height': 512, 'min_..._value': None, 'p': 1.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 158\u001b[0m\n\u001b[1;32m    152\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optim, total_loss, metrics)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Datasets\u001b[39;00m\n\u001b[1;32m    156\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m Dataset(\n\u001b[1;32m    157\u001b[0m     x_train_dir, y_train_dir, \n\u001b[0;32m--> 158\u001b[0m     augmentation\u001b[38;5;241m=\u001b[39m\u001b[43mget_training_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    159\u001b[0m     preprocessing\u001b[38;5;241m=\u001b[39mget_preprocessing(preprocess_input)\n\u001b[1;32m    160\u001b[0m )\n\u001b[1;32m    162\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m Dataset(\n\u001b[1;32m    163\u001b[0m     x_valid_dir, y_valid_dir, \n\u001b[1;32m    164\u001b[0m     augmentation\u001b[38;5;241m=\u001b[39mget_validation_augmentation(),\n\u001b[1;32m    165\u001b[0m     preprocessing\u001b[38;5;241m=\u001b[39mget_preprocessing(preprocess_input)\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    168\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m Dataloader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 110\u001b[0m, in \u001b[0;36mget_training_augmentation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_training_augmentation\u001b[39m():\n\u001b[1;32m    107\u001b[0m     train_transform \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    108\u001b[0m         A\u001b[38;5;241m.\u001b[39mHorizontalFlip(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m    109\u001b[0m         A\u001b[38;5;241m.\u001b[39mShiftScaleRotate(scale_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, rotate_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, shift_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, border_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m--> 110\u001b[0m         \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPadIfNeeded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_apply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mborder_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    111\u001b[0m         A\u001b[38;5;241m.\u001b[39mRandomCrop(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, always_apply\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    112\u001b[0m         A\u001b[38;5;241m.\u001b[39mIAAAdditiveGaussianNoise(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m    113\u001b[0m         A\u001b[38;5;241m.\u001b[39mOneOf([A\u001b[38;5;241m.\u001b[39mCLAHE(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), A\u001b[38;5;241m.\u001b[39mRandomBrightness(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), A\u001b[38;5;241m.\u001b[39mRandomGamma(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)], p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m),\n\u001b[1;32m    114\u001b[0m         A\u001b[38;5;241m.\u001b[39mOneOf([A\u001b[38;5;241m.\u001b[39mIAASharpen(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), A\u001b[38;5;241m.\u001b[39mBlur(blur_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)], p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m),\n\u001b[1;32m    115\u001b[0m         A\u001b[38;5;241m.\u001b[39mOneOf([A\u001b[38;5;241m.\u001b[39mRandomContrast(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), A\u001b[38;5;241m.\u001b[39mHueSaturationValue(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)], p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m),\n\u001b[1;32m    116\u001b[0m         A\u001b[38;5;241m.\u001b[39mLambda(mask\u001b[38;5;241m=\u001b[39mround_clip_0_1)\n\u001b[1;32m    117\u001b[0m     ]\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m A\u001b[38;5;241m.\u001b[39mCompose(train_transform)\n",
      "File \u001b[0;32m~/pesquisa/segmentation-of-blood-vessels-in-retinal-images/.venv/lib/python3.11/site-packages/albumentations/core/validation.py:35\u001b[0m, in \u001b[0;36mValidatedTransformMeta.__new__.<locals>.custom_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         full_kwargs[parameter_name] \u001b[38;5;241m=\u001b[39m parameter\u001b[38;5;241m.\u001b[39mdefault\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# No try-except block needed as we want the exception to propagate naturally\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mdct\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInitSchema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfull_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m validated_kwargs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name_arg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/pesquisa/segmentation-of-blood-vessels-in-retinal-images/.venv/lib/python3.11/site-packages/pydantic/main.py:209\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    208\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    211\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    215\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    216\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for InitSchema\n  Value error, If 'border_mode' is set to 'BORDER_CONSTANT', 'value' must be provided. [type=value_error, input_value={'min_height': 512, 'min_..._value': None, 'p': 1.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Requirements\n",
    "# - keras >= 2.2.0 or tensorflow >= 1.13\n",
    "# - segmentation-models==1.0.*\n",
    "# - albumentations==0.3.0\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models as sm\n",
    "import albumentations as A\n",
    "\n",
    "# %%\n",
    "DATA_DIR = './drive_png/'\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, 'training', 'input')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'training', 'target')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'test', 'input')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'test', 'target')\n",
    "\n",
    "# %% [markdown]\n",
    "# # Dataloader and utility functions \n",
    "\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def denormalize(x):\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"DRIVE Dataset. Read images, apply augmentation and preprocessing transformations.\"\"\"\n",
    "    \n",
    "    def __init__(self, images_dir, masks_dir, augmentation=None, preprocessing=None):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id.replace('_training', '_manual1')) for image_id in self.ids]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Read data\n",
    "        image = cv2.imread(self.images_fps[i], cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        mask = (mask > 0).astype(np.float32)  # Convert to binary mask\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "class Dataloader(keras.utils.Sequence):\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = [self.dataset[j] for j in range(start, stop)]\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)\n",
    "\n",
    "# %%\n",
    "# Data augmentation\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, always_apply=True, border_mode=0),\n",
    "        A.RandomCrop(height=512, width=512, always_apply=True),\n",
    "        A.IAAAdditiveGaussianNoise(p=0.2),\n",
    "        A.OneOf([A.CLAHE(p=1), A.RandomBrightness(p=1), A.RandomGamma(p=1)], p=0.9),\n",
    "        A.OneOf([A.IAASharpen(p=1), A.Blur(blur_limit=3, p=1)], p=0.9),\n",
    "        A.OneOf([A.RandomContrast(p=1), A.HueSaturationValue(p=1)], p=0.9),\n",
    "        A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    test_transform = [A.PadIfNeeded(512, 512)]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    return A.Compose([A.Lambda(image=preprocessing_fn)])\n",
    "\n",
    "# %%\n",
    "BACKBONE = 'efficientnetb3'\n",
    "BATCH_SIZE = 4\n",
    "CLASSES = ['vessel']\n",
    "LR = 0.0001\n",
    "EPOCHS = 50\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "n_classes = 1  # Binary segmentation\n",
    "activation = 'sigmoid'\n",
    "\n",
    "# Create model\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
    "\n",
    "# Define optimizer\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Define losses and metrics\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "focal_loss = sm.losses.BinaryFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), 'accuracy', 'precision', 'recall']\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optim, total_loss, metrics)\n",
    "\n",
    "# %%\n",
    "# Datasets\n",
    "train_dataset = Dataset(\n",
    "    x_train_dir, y_train_dir, \n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input)\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input)\n",
    ")\n",
    "\n",
    "train_dataloader = Dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = Dataloader(valid_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# %%\n",
    "# Callbacks and training\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_dataloader, \n",
    "    steps_per_epoch=len(train_dataloader), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=valid_dataloader, \n",
    "    validation_steps=len(valid_dataloader),\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Model evaluation\n",
    "test_dataset = Dataset(\n",
    "    x_valid_dir, y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocess_input)\n",
    ")\n",
    "\n",
    "test_dataloader = Dataloader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.load_weights('best_model.h5')\n",
    "scores = model.evaluate_generator(test_dataloader)\n",
    "\n",
    "print(\"Loss: {:.5}\".format(scores[0]))\n",
    "for metric, value in zip(metrics, scores[1:]):\n",
    "    print(f\"{metric}: {value:.5}\")\n",
    "\n",
    "# %%\n",
    "# Visualize results\n",
    "n = 5\n",
    "ids = np.random.choice(np.arange(len(test_dataset)), size=n)\n",
    "\n",
    "for i in ids:\n",
    "    image, gt_mask = test_dataset[i]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    pr_mask = model.predict(image).round()\n",
    "    \n",
    "    visualize(\n",
    "        image=denormalize(image.squeeze()),\n",
    "        gt_mask=gt_mask.squeeze(),\n",
    "        pr_mask=pr_mask.squeeze(),\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
